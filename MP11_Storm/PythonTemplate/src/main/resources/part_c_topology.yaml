# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---

# topology definition
# name to be used when submitting
name: "part-C"

# TODO
# Task: implement your topology for part c

# topology configuration
# this will be passed to the submitter as a map of config options
config:
    storm.local.hostname: "localhost"
    topology.max.task.parallelism: 3
    # set this to true if you want to see more debug log
    # set it to false before submitting
    topology.debug: false
    # redis configuration, useful in store bolt
    redis:
      host: "localhost"
      port: 6379
      db: 0
      password: "uiuc_cs498_mp11"
      timeout: 2000
      # redis hash key for part C is "partCWordCount"
      hashKey: "partCWordCount"
    # Hint: you can set input file path here
    # make sure it's "/tmp/data.txt" in your final submission
    infile : "/tmp/data.txt"

# spout definitions
spouts:
  - id: "file_reader_spout"
    className: "org.apache.storm.flux.wrappers.spouts.FluxShellSpout"
    constructorArgs:
      # Command line
      - [ "python", "file_reader_spout.py" ]
      # Output field(s)
      - [ "sentence" ]
    # parallelism hint
    parallelism: 1

# bolt definitions
bolts:
  # Hint: the new normalize bolt you need implement in this part is
  # multilang/resources/normalizer_bolt.py
  - id: "split_sentence_bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      - [ "python","split_sentence_bolt.py" ]
      - [ "word" ]
    parallelism: 3

  - id: "normalizer_bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      - [ "python","normalizer_bolt.py" ]
      - [ "word" ]
    parallelism: 3

  - id: "word_count_bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      # Command line
      - [ "python","word_count_bolt.py" ]
      # Output field(s)
      - [ "word","count" ]
    parallelism: 2

  - id: "word_count_store_bolt"
    className: "org.apache.storm.flux.wrappers.bolts.FluxShellBolt"
    constructorArgs:
      - [ "python","word_count_store_bolt.py" ]
    parallelism: 3

# stream definitions
# stream definitions define connections between spouts and bolts.
streams:
  # Hint: add new normalize bolt into the topology
 # Task: pipe output of sentences generating spout to split bolt
   - name: "Spout --> Splitter" # name isn't used (placeholder for logging, UI, etc.)
      # The stream emitter
     from: "file_reader_spout"
      # The stream consumer
     to: "split_sentence_bolt"
      # Grouping type
     grouping:
      type: SHUFFLE

   # Hint: add new normalize bolt into the topology
   - name: "Splitter -> Normalizer"
     from: "split_sentence_bolt"
     to: "normalizer_bolt"
     grouping:
       type: SHUFFLE
#       # field(s) to group on
#       args: [ "word" ]

  # Task: pipe output of split bolt to word count bolt
  # Hint: choose the right grouping type to make problem easier
   - name: "Normalizer -> Counter"
     from: "normalizer_bolt"
     to: "word_count_bolt"
     grouping:
      type: FIELDS
        # field(s) to group on
      args: ["word"]

  # Task: pipe output of word count bolt to redis store bolt
   - name: "Counter -> redis"
     from: "word_count_bolt"
     to: "word_count_store_bolt"
     grouping:
      type: SHUFFLE